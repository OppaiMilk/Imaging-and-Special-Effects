{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forbidden city\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "# brightness adjust\n",
    "img = Image.open('../Pic/city.png')\n",
    "img_enhancer = ImageEnhance.Brightness(img)\n",
    "enhanced_city = img_enhancer.enhance(0.75)\n",
    "\n",
    "# sharpening\n",
    "sharpened_city = enhanced_city.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "# compositing\n",
    "img2 = Image.open('../Pic/sharpen_sky.png').convert(\"RGBA\")\n",
    "img2 = img2.resize((img.width, img.height), Image.LANCZOS)\n",
    "result = Image.alpha_composite(img2, sharpened_city)\n",
    "\n",
    "result.save('../Processed Pic/modified_city.png')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dragon\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "# sharpening\n",
    "img = Image.open('../Pic/dragon.png')\n",
    "sharpened_dragon = img.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "# contrast adjust\n",
    "enhancer = ImageEnhance.Contrast(sharpened_dragon)\n",
    "result = enhancer.enhance(2)\n",
    "\n",
    "result.save('../Processed Pic/modified_dragon.png')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moon\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def barrel_distort(image, k1, k2, k3):\n",
    "    width, height = image.size\n",
    "    x_center = width / 2\n",
    "    y_center = height / 2\n",
    "    \n",
    "    # Create the coordinate grid\n",
    "    x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    x = x - x_center\n",
    "    y = y - y_center\n",
    "    \n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    \n",
    "    # Calculate the distortion factor\n",
    "    theta = np.arctan2(y, x)\n",
    "    r_distorted = r * (1 + k1 * r**2 + k2 * r**4 + k3 * r**6)\n",
    "    \n",
    "    # Map the distorted coordinates back to image coordinates\n",
    "    x_distorted = r_distorted * np.cos(theta) + x_center\n",
    "    y_distorted = r_distorted * np.sin(theta) + y_center\n",
    "    \n",
    "    # Use bilinear interpolation to create the distorted image\n",
    "    distorted_image = np.array(image)\n",
    "    new_image = np.zeros_like(distorted_image)\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            x_new = int(np.clip(x_distorted[i, j], 0, width - 1))\n",
    "            y_new = int(np.clip(y_distorted[i, j], 0, height - 1))\n",
    "            new_image[i, j] = distorted_image[y_new, x_new]\n",
    "    \n",
    "    return Image.fromarray(new_image)\n",
    "\n",
    "def chromatic_aberration(image, shift_red, shift_blue):\n",
    "    r, g, b = image.split()\n",
    "\n",
    "    # Convert channels to numpy arrays\n",
    "    r = np.array(r)\n",
    "    g = np.array(g)\n",
    "    b = np.array(b)\n",
    "\n",
    "    # Create shifted channels\n",
    "    def shift_channel(channel, shift_x, shift_y):\n",
    "        shifted = np.zeros_like(channel)\n",
    "        if shift_y > 0:\n",
    "            shifted[shift_y:] = channel[:-shift_y]\n",
    "        elif shift_y < 0:\n",
    "            shifted[:shift_y] = channel[-shift_y:]\n",
    "        else:\n",
    "            shifted[:] = channel[:]\n",
    "            \n",
    "        if shift_x > 0:\n",
    "            shifted[:, shift_x:] = shifted[:, :-shift_x]\n",
    "        elif shift_x < 0:\n",
    "            shifted[:, :shift_x] = shifted[:, -shift_x:]\n",
    "        \n",
    "        return shifted\n",
    "    \n",
    "    r_shifted = shift_channel(r, *shift_red)\n",
    "    b_shifted = shift_channel(b, *shift_blue)\n",
    "\n",
    "    # Combine the channels back into an image\n",
    "    result = np.stack([r_shifted, g, b_shifted], axis=-1)\n",
    "    result_image = Image.fromarray(result)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open('../Pic/moon.png').convert('RGB')\n",
    "\n",
    "# barrel distortion\n",
    "result_barrel_distort = barrel_distort(img, 0.000000000001, 0.000000000001, 0.000000000001)\n",
    "\n",
    "# chromatic aberration distortion\n",
    "result = chromatic_aberration(result_barrel_distort, (-5, -5), (5, 5))\n",
    "\n",
    "result.save('../Processed Pic/modified_moon.png')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making reflection for objects\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "# dragon reflection\n",
    "img = Image.open('../Processed Pic/modified_dragon.png')\n",
    "img = img.filter(ImageFilter.GaussianBlur)\n",
    "img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "img = img.resize((422, 100))\n",
    "\n",
    "# opacity adjust\n",
    "r, g, b, a = img.split()\n",
    "a = a.point(lambda p: p * 0.25)\n",
    "img = Image.merge(\"RGBA\", (r, g, b, a))\n",
    "\n",
    "img.save('../Processed Pic/reflection_dragon.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay\n",
    "from PIL import Image \n",
    "  \n",
    "img = Image.open('../Processed Pic/modified_city.png')  \n",
    "img2 = Image.open('../Processed Pic/modified_dragon.png') \n",
    "img3 = Image.open('../Processed Pic/reflection_dragon.png')\n",
    "img4 = Image.open('../Pic/shining_light.jpg')\n",
    "img5 = Image.open('../Pic/boat_people.png')\n",
    "img6 = Image.open('../Processed Pic/modified_moon2.png')\n",
    "  \n",
    "# dragon\n",
    "img.paste(img2, (1000, 50), mask = img2) \n",
    "\n",
    "# dragon reflection\n",
    "img.paste(img3, (1000, 1000), mask = img3)\n",
    "\n",
    "# people on boats\n",
    "img.paste(img5, (50, 650), mask = img5)\n",
    "\n",
    "# moon\n",
    "img.paste(img6, (0, 0), mask = img6)\n",
    "\n",
    "# shining light effect on dragon\n",
    "if img4.mode != 'L':\n",
    "    img4 = img4.convert('L')\n",
    "\n",
    "if img4.size != img.size:\n",
    "    img4 = img4.resize(img.size)\n",
    "\n",
    "img4 = img4.convert('RGB')\n",
    "img = img.convert('RGB')\n",
    "\n",
    "result_image = Image.blend(img, img4.convert('RGB'), 0.4)\n",
    "\n",
    "result_image.save('../Processed Pic/result_v1.jpg')\n",
    "result_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../Processed Pic/result_v1.mp4.\n",
      "MoviePy - Writing audio in result_v1TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../Processed Pic/result_v1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../Processed Pic/result_v1.mp4\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip\n",
    "import numpy as np\n",
    "\n",
    "# Open base image\n",
    "img = Image.open('../Processed Pic/result_v1.jpg').convert('RGBA')\n",
    "\n",
    "# Open GIF\n",
    "gif = Image.open('../Pic/shiny.gif')\n",
    "gif2 = Image.open('../Pic/shiny2.gif')\n",
    "\n",
    "# Prepare a list to hold frames\n",
    "frames = []\n",
    "\n",
    "# Get the number of frames (use the longer of the two GIFs)\n",
    "n_frames = max(gif.n_frames, gif2.n_frames)\n",
    "\n",
    "# Loop through each frame\n",
    "for i in range(n_frames):\n",
    "    # Create a new image with the same size as the base image\n",
    "    new_frame = img.copy()\n",
    "\n",
    "    # Process first GIF\n",
    "    if i < gif.n_frames:\n",
    "        frame1 = gif.seek(i)\n",
    "        frame1 = Image.fromarray(np.array(gif.convert('RGBA')))\n",
    "        new_frame.paste(frame1, (850, 0), mask=frame1)\n",
    "\n",
    "    # Process second GIF\n",
    "    if i < gif2.n_frames:\n",
    "        frame2 = gif2.seek(i)\n",
    "        frame2 = Image.fromarray(np.array(gif2.convert('RGBA')))\n",
    "        new_frame.paste(frame2, (1110, 220), mask=frame2)\n",
    "\n",
    "    # Convert PIL Image to numpy array and append to frames list\n",
    "    frames.append(np.array(new_frame.convert('RGB')))\n",
    "\n",
    "# Create a video clip\n",
    "clip = ImageSequenceClip(frames, fps=24)\n",
    "\n",
    "# adding sound effect for video\n",
    "audio = AudioFileClip(\"../Pic/beam_charge.mp3\")\n",
    "video = clip.set_audio(audio)\n",
    "\n",
    "# looping video to ensure video same duration as audio\n",
    "video = video.loop(duration=audio.duration)\n",
    "\n",
    "# Write the result to a file\n",
    "video.write_videofile(\"../Processed Pic/result_v1.mp4\", codec=\"libx264\", audio_codec=\"aac\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
