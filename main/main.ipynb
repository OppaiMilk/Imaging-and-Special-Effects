{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Function"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scales the inputimage by scale_factor\n",
    "def scale_image(image, scale_factor):\n",
    "    width, height = image.size\n",
    "    new_width = int(width * scale_factor)\n",
    "    new_height = int(height * scale_factor)\n",
    "    return image.resize((new_width, new_height))\n",
    "\n",
    "# Removes background from the input image\n",
    "def remove_background(image):\n",
    "    new_image = remove(image)\n",
    "    return new_image\n",
    "\n",
    "# Adjusts brightness of the input image by the specified factor\n",
    "def adjust_brightness(image, factor):\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "# Adjust the opacity of the input image by the specified factor\n",
    "def crop_and_adjust_opacity(image, opacity_factor):\n",
    "    # Crop to visible content\n",
    "    alpha = image.split()[-1]\n",
    "    bbox = alpha.getbbox()\n",
    "    cropped = image.crop(bbox)\n",
    "    \n",
    "    # Adjust opacity\n",
    "    pixels = cropped.load()\n",
    "    width, height = cropped.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            r, g, b, a = pixels[x, y]\n",
    "            pixels[x, y] = (r, g, b, int(a * opacity_factor))\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "# Adjusts blur of the input image by the specified radius\n",
    "def blur_image(image, radius=2):\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius))\n",
    "\n",
    "# Pastes the overlay image onto the background image with rotation\n",
    "def paste_with_rotation(background, overlay, x_factor, y_factor, rotation_degrees):\n",
    "    rotated_overlay = overlay.rotate(rotation_degrees, expand=True)\n",
    "    bg_width, bg_height = background.size\n",
    "    offset_x = int(bg_width * x_factor)\n",
    "    offset_y = int(bg_height * y_factor)\n",
    "    paste_x = offset_x - rotated_overlay.width // 2\n",
    "    paste_y = offset_y - rotated_overlay.height // 2\n",
    "    background.paste(rotated_overlay, (paste_x, paste_y), rotated_overlay)\n",
    "\n",
    "# Creates a shadow effect for the input image\n",
    "def create_shadow(image, blur_radius=10, opacity=0.5, squash_factor=0.5, squash_axis=\"y\"):\n",
    "    shadow = Image.new(\"RGBA\", image.size, (0, 0, 0, 0))\n",
    "    for x in range(image.width):\n",
    "        for y in range(image.height):\n",
    "            _, _, _, a = image.getpixel((x, y))\n",
    "            if a > 0:\n",
    "                shadow.putpixel((x, y), (0, 0, 0, int(255 * opacity)))\n",
    "\n",
    "    shadow = shadow.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "\n",
    "    if squash_axis.lower() == \"x\":\n",
    "        new_width = int(shadow.width * squash_factor)\n",
    "        shadow = shadow.resize((new_width, shadow.height), Image.LANCZOS)\n",
    "    elif squash_axis.lower() == \"y\":\n",
    "        new_height = int(shadow.height * squash_factor)\n",
    "        shadow = shadow.resize((shadow.width, new_height), Image.LANCZOS)\n",
    "    else:\n",
    "        raise ValueError(\"squash_axis must be either x or y\")\n",
    "\n",
    "    return shadow\n",
    "\n",
    "# Adds a vignette effect to the input image with the specified strength\n",
    "def add_vignette(image, strength=0.75):\n",
    "    width, height = image.size\n",
    "    mask = Image.new(\"L\", (width, height))\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            distance = min(1.0, ((x - width/2.0)**2 + (y - height/2.0)**2) / ((width/2.0)**2 + (height/2.0)**2))\n",
    "            darkness = int(255 * (1 - distance * strength))\n",
    "            draw.point((x, y), fill=darkness)\n",
    "    \n",
    "    return Image.composite(image, Image.new(\"RGB\", (width, height), \"black\"), mask)\n",
    "\n",
    "def create_pisa_animation(image, fps, num_frames, min_factor=0.85, max_factor=1.2, amplitude=6.5, frequency=144, shake_start=0.25, shake_end=0.75, shake_amplitude=5):\n",
    "    image.thumbnail((3264, 2448), Image.LANCZOS)\n",
    "    width, height = image.size\n",
    "    pixels = image.load()\n",
    "    frames = []\n",
    "\n",
    "    for i in tqdm(range(num_frames), desc=\"Creating animation frames\", unit=\"frame\"):\n",
    "        new_image = Image.new(\"RGBA\", (3264, 2448), (0, 0, 0, 0))\n",
    "        new_pixels = new_image.load()\n",
    "        phase_shift = i / num_frames\n",
    "        \n",
    "        # Apply shaking effect if within the specified time range\n",
    "        shake_offset_x = 0\n",
    "        shake_offset_y = 0\n",
    "        if shake_start <= phase_shift < shake_end:\n",
    "            shake_offset_x = int(shake_amplitude * (np.random.random() - 0.5) * 2)  # Random shake in x direction\n",
    "            shake_offset_y = int(shake_amplitude * (np.random.random() - 0.5) * 2)  # Random shake in y direction\n",
    "\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                offset = int(amplitude * np.sin(2 * np.pi * (x / frequency + phase_shift)))\n",
    "                new_x = x + shake_offset_x\n",
    "                new_y = y + offset + shake_offset_y\n",
    "                if 0 <= new_x < width and 0 <= new_y < height:\n",
    "                    new_pixels[new_x, new_y] = pixels[x, y]\n",
    "\n",
    "        factor = min_factor + (max_factor - min_factor) * abs(np.sin(2 * np.pi * i / num_frames))\n",
    "        enhancer = ImageEnhance.Brightness(new_image)\n",
    "        bright_wave_frame = enhancer.enhance(factor)\n",
    "\n",
    "        zoom_factor = 1.1\n",
    "        zoomed_width = int(width * zoom_factor)\n",
    "        zoomed_height = int(height * zoom_factor)\n",
    "        zoomed_bright_wave_frame = bright_wave_frame.resize((zoomed_width, zoomed_height), Image.LANCZOS)\n",
    "\n",
    "        canvas = Image.new(\"RGBA\", (3264, 2448), (0, 0, 0, 0))\n",
    "        canvas.paste(zoomed_bright_wave_frame, ((3264 - zoomed_width) // 2, (2448 - zoomed_height) // 2))\n",
    "\n",
    "        frames.append(canvas)\n",
    "\n",
    "    return frames\n",
    "\n",
    "def images_to_video(image_folder, video_file, fps=24):\n",
    "    images = [img for img in sorted(os.listdir(image_folder)) if img.endswith(\".png\")]\n",
    "\n",
    "    if not images:\n",
    "        raise ValueError(\"No PNG images found in the directory.\")\n",
    "\n",
    "    first_frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Unable to read the image file {images[0]}\")\n",
    "    height, width, layers = first_frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(video_file, fourcc, fps, (width, height))\n",
    "\n",
    "    for image in tqdm(images, desc=\"Creating video\", unit = \"frame\"):\n",
    "        frame = cv2.imread(os.path.join(image_folder, image))\n",
    "        if frame is None:\n",
    "            print(f\"Warning: Unable to read the image file {image}. Skipping...\")\n",
    "            continue\n",
    "        if frame.shape[0] != height or frame.shape[1] != width:\n",
    "            print(f\"Warning: The image file {image} has different dimensions. Resizing...\")\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video saved as {video_file}\")\n",
    "\n",
    "def add_audio_to_video(video_path, audio_path, output_path, fade_duration=3, audio_start_frac=0, audio_end_frac=1):\n",
    "    video = VideoFileClip(video_path)\n",
    "    background_music = AudioFileClip(audio_path)\n",
    "\n",
    "    audio_start = video.duration * audio_start_frac\n",
    "    audio_end = video.duration * audio_end_frac\n",
    "\n",
    "    if audio_end > video.duration:\n",
    "        audio_end = video.duration\n",
    "    \n",
    "    audio_duration = audio_end - audio_start\n",
    "    background_music = background_music.subclip(0, min(audio_duration, background_music.duration))\n",
    "\n",
    "    background_music = audio_fadein(background_music, duration=fade_duration)\n",
    "    background_music = audio_fadeout(background_music, duration=fade_duration)\n",
    "    background_music = background_music.volumex(0.8)\n",
    "\n",
    "    if video.audio is None:\n",
    "        final_audio = background_music.set_start(audio_start)\n",
    "    else:\n",
    "        background_music = background_music.set_start(audio_start)\n",
    "        final_audio = CompositeAudioClip([video.audio, background_music])\n",
    "\n",
    "    final_video = video.set_audio(final_audio)\n",
    "    final_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    video.close()\n",
    "    background_music.close()\n",
    "    final_video.close()\n",
    "    \n",
    "def apply_sobel(image):\n",
    "    rgba_channels = cv2.split(image)\n",
    "    rgb_image = cv2.merge(rgba_channels[:3])\n",
    "    alpha_channel = rgba_channels[3]\n",
    "\n",
    "    rgb_gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobel_x = cv2.Sobel(rgb_gray, cv2.CV_64F, 1, 0, ksize=1)\n",
    "    sobel_y = cv2.Sobel(rgb_gray, cv2.CV_64F, 0, 1, ksize=1)\n",
    "    sobel_magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
    "    sobel_magnitude = cv2.convertScaleAbs(sobel_magnitude)\n",
    "\n",
    "    sobel_rgba = cv2.merge([sobel_magnitude, sobel_magnitude, sobel_magnitude, alpha_channel])\n",
    "\n",
    "    return sobel_rgba\n",
    "\n",
    "def apply_perspective_transform(image, top_shrink=0.5, bottom_expand=1.2):\n",
    "    original_points = np.float32([[0, 0], [image.shape[1], 0],\n",
    "                                  [image.shape[1], image.shape[0]],\n",
    "                                  [0, image.shape[0]]])\n",
    "\n",
    "    desired_points = np.float32([[int(image.shape[1] * (1 - top_shrink) / 2), int(image.shape[0] * top_shrink)],\n",
    "                                 [int(image.shape[1] * (1 + top_shrink) / 2), int(image.shape[0] * top_shrink)],\n",
    "                                 [int(image.shape[1] * (1 + bottom_expand) / 2), int(image.shape[0] * bottom_expand)],\n",
    "                                 [int(image.shape[1] * (1 - bottom_expand) / 2), int(image.shape[0] * bottom_expand)]])\n",
    "\n",
    "    perspective_matrix = cv2.getPerspectiveTransform(original_points, desired_points)\n",
    "\n",
    "    warped_image = cv2.warpPerspective(image, perspective_matrix, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    return warped_image\n",
    "\n",
    "def apply_color_tint(image_np, threshold, custom_color_hex, tint_strength):\n",
    "    white_mask = (image_np[:,:,0] > threshold) & \\\n",
    "                 (image_np[:,:,1] > threshold) & \\\n",
    "                 (image_np[:,:,2] > threshold)\n",
    "\n",
    "    custom_color_rgb = np.array(ImageColor.getcolor(custom_color_hex, \"RGB\"))\n",
    "    \n",
    "    image_np[white_mask, :3] = image_np[white_mask, :3] * (1 - tint_strength) + custom_color_rgb * tint_strength\n",
    "\n",
    "    tinted_image = Image.fromarray(image_np.astype(np.uint8))\n",
    "    return tinted_image\n",
    "\n",
    "def bob_video(input_path, output_path, overlay_path, output_width, output_height, zoom_factor, bob_amplitude, bob_frequency):\n",
    "    overlayed_video = VideoFileClip(input_path)\n",
    "\n",
    "    scale_factor = max(output_width / overlayed_video.w, output_height / overlayed_video.h)\n",
    "    resized_video = overlayed_video.resize(scale_factor)\n",
    "\n",
    "    background = ColorClip(size=(output_width, output_height), color=(0,0,0)).set_duration(overlayed_video.duration)\n",
    "\n",
    "    video_pos = ((output_width - resized_video.w) // 2, (output_height - resized_video.h) // 2)\n",
    "\n",
    "    zoomed_bobbing_video = resized_video.fl(\n",
    "        lambda get_frame, t: cv2.warpAffine(\n",
    "            get_frame(t),\n",
    "            np.float32([\n",
    "                [zoom_factor, 0, -zoom_factor * get_frame(t).shape[1] * 0.5 + get_frame(t).shape[1] * 0.5],\n",
    "                [0, zoom_factor, -zoom_factor * get_frame(t).shape[0] * 0.5 + get_frame(t).shape[0] * 0.5 + \n",
    "                 bob_amplitude * np.sin(2 * np.pi * bob_frequency * t)]\n",
    "            ]),\n",
    "            (get_frame(t).shape[1], get_frame(t).shape[0])\n",
    "        )\n",
    "    ).set_position(video_pos)\n",
    "\n",
    "    composed_video = CompositeVideoClip([background, zoomed_bobbing_video])\n",
    "\n",
    "    shipdeck = Image.open(overlay_path)\n",
    "    resized_shipdeck = shipdeck.resize((output_width, output_height), Image.LANCZOS)\n",
    "    shipdeck_array = np.array(resized_shipdeck)\n",
    "\n",
    "    shipdeck_clip = ImageClip(shipdeck_array).set_duration(overlayed_video.duration)\n",
    "\n",
    "    final_clip = CompositeVideoClip([composed_video, shipdeck_clip])\n",
    "\n",
    "    final_clip.write_videofile(output_path)\n",
    "\n",
    "def adjust_video_color_balance(frame, red_factor, green_factor, blue_factor):\n",
    "    frame = frame.astype(np.float32)\n",
    "    frame[:, :, 0] *= red_factor\n",
    "    frame[:, :, 1] *= green_factor\n",
    "    frame[:, :, 2] *= blue_factor\n",
    "    frame = np.clip(frame, 0, 255).astype(np.uint8)\n",
    "    return frame\n",
    "\n",
    "def colorize_image(image, prototxt_path, model_path, points_path):\n",
    "    net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "    pts = np.load(points_path)\n",
    "\n",
    "    class8 = net.getLayerId(\"class8_ab\")\n",
    "    conv8 = net.getLayerId(\"conv8_313_rh\")\n",
    "    pts = pts.transpose().reshape(2, 313, 1, 1)\n",
    "    net.getLayer(class8).blobs = [pts.astype(\"float32\")]\n",
    "    net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]\n",
    "\n",
    "    scaled = image.astype(\"float32\") / 255.0\n",
    "    lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    resized = cv2.resize(lab, (224, 224))\n",
    "    L = cv2.split(resized)[0]\n",
    "    L -= 50\n",
    "\n",
    "    net.setInput(cv2.dnn.blobFromImage(L))\n",
    "    ab = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
    "\n",
    "    ab = cv2.resize(ab, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    L = cv2.split(lab)[0]\n",
    "    colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n",
    "\n",
    "    colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
    "    colorized = np.clip(colorized, 0, 1)\n",
    "\n",
    "    colorized = (255 * colorized).astype(\"uint8\")\n",
    "\n",
    "    return colorized\n",
    "\n",
    "def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl_l_channel = clahe.apply(l_channel)\n",
    "\n",
    "    merged_lab = cv2.merge((cl_l_channel, a_channel, b_channel))\n",
    "    result = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_panorama(image1, image2, overlap_percent=30, feather_width=50):\n",
    "    overlap_width = int(image1.width * overlap_percent / 100)\n",
    "\n",
    "    new_width = image1.width + image2.width - overlap_width\n",
    "    new_height = max(image1.height, image2.height)\n",
    "    \n",
    "    panorama = Image.new('RGB', (new_width, new_height))\n",
    "    \n",
    "    # Paste the second image\n",
    "    panorama.paste(image2, (image1.width - overlap_width, 0))\n",
    "    \n",
    "    # Create a mask for feathering the first image\n",
    "    mask = Image.new('L', image1.size, 255)\n",
    "    mask_draw = ImageDraw.Draw(mask)\n",
    "    \n",
    "    for x in range(feather_width):\n",
    "        opacity = int(255 * (1 - x / feather_width))\n",
    "        mask_draw.line([(image1.width - feather_width + x, 0), \n",
    "                        (image1.width - feather_width + x, image1.height)], \n",
    "                       fill=opacity)\n",
    "    \n",
    "    # Create a copy of image1 for feathering\n",
    "    image1_feathered = image1.copy()\n",
    "    if image1_feathered.mode != 'RGBA':\n",
    "        image1_feathered = image1_feathered.convert('RGBA')\n",
    "    \n",
    "    # Apply the feathering mask to the copy\n",
    "    image1_feathered.putalpha(mask)\n",
    "    \n",
    "    # Paste the feathered copy of image1\n",
    "    panorama.paste(image1_feathered, (0, 0), mask=image1_feathered)\n",
    "    \n",
    "    return panorama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m resized_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (new_width, new_height), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_CUBIC)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Display the resized image\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResized Image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresized_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     21\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": []
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not load image. Please check the file path and try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\lingj\\AppData\\Local\\Temp\\ipykernel_21708\\2730532717.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  image_path = \"..\\Pic\\shirine.jpeg\"\n"
     ]
    }
   ],
   "source": [
    "image_path = \"..\\Pic\\shirine.jpeg\"\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded correctly\n",
    "if img is None:\n",
    "    print(\"Error: Could not load image. Please check the file path and try again.\")\n",
    "else:\n",
    "    # New dimensions\n",
    "    new_width = 800\n",
    "    new_height = 600\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Display the resized image\n",
    "    cv2.imshow('Resized Image', resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
